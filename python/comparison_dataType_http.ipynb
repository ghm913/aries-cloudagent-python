{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2df63618-28dd-4a79-8f14-f7f0998c45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib import cycler\n",
    "from IPython.display import clear_output\n",
    "\n",
    "prometheus_url = 'http://localhost:9090'  #  Prometheus server URL\n",
    "\n",
    "cpu_query = 'sum(irate(node_cpu_seconds_total{instance=\"node-exporter:9100\", job=\"node_exporter\", mode!=\"idle\"}[5m])) / scalar(count(count(node_cpu_seconds_total{instance=\"node-exporter:9100\", job=\"node_exporter\"}) by (cpu)))'\n",
    "ram_query = 'node_memory_MemAvailable_bytes{instance=\"node-exporter:9100\", job=\"node_exporter\"} / node_memory_MemTotal_bytes{instance=\"node-exporter:9100\", job=\"node_exporter\"}'\n",
    "\n",
    "def fetch_data(query, start, end):\n",
    "    response = requests.get(f'{prometheus_url}/api/v1/query_range', params={\n",
    "        'query': query,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'step': '1s'\n",
    "    })\n",
    "    response.raise_for_status()  \n",
    "    results = response.json()['data']['result']\n",
    "    print(f\"Data for interval {start} to {end}: {results}\")\n",
    "    return results\n",
    "\n",
    "def process_data(data):\n",
    "    if not data:\n",
    "        print(\"No data returned from Prometheus.\")\n",
    "        return [], []\n",
    "    timestamps = [pd.to_datetime(point[0], unit='s') for point in data[0]['values']]\n",
    "    values = [float(point[1]) for point in data[0]['values']]\n",
    "    return timestamps, values\n",
    "\n",
    "def normalize_timestamps(timestamps):\n",
    "    start_time = timestamps[0] if timestamps else None\n",
    "    return [(ts - start_time).total_seconds() for ts in timestamps], start_time\n",
    "\n",
    "def plot_grouped_data(data_groups, ylabel, title, output_file):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    plt.rc('axes', prop_cycle=(cycler('color', plt.cm.tab20.colors)))\n",
    "\n",
    "    for normalized_timestamps, values, label in data_groups:\n",
    "        plt.plot(normalized_timestamps, values, label=label)\n",
    "\n",
    "    plt.xlabel('Seconds from Start')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_avg_data(values_dict, data_types, ylabel, title, output_file, variable_name, is_throughput=False):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.rc('axes', prop_cycle=(cycler('color', plt.cm.tab20.colors)))\n",
    "\n",
    "    if is_throughput:\n",
    "        all_throughput_values = [value for sublist in values_dict.values() for value in sublist]\n",
    "        max_throughput = max(all_throughput_values)\n",
    "        if max_throughput > 1000000:\n",
    "            throughput_unit = \"MB/s\"\n",
    "            throughput_scale = 1 / (1024 * 1024)\n",
    "        elif max_throughput > 1000:\n",
    "            throughput_unit = \"KB/s\"\n",
    "            throughput_scale = 1 / 1024\n",
    "        else:\n",
    "            throughput_unit = \"B/s\"\n",
    "            throughput_scale = 1\n",
    "        \n",
    "        for http_version in values_dict:\n",
    "            values_dict[http_version] = [value * throughput_scale for value in values_dict[http_version]]\n",
    "        \n",
    "        ylabel = f'Average Throughput ({throughput_unit})'\n",
    "\n",
    "    for http_version, values in values_dict.items():\n",
    "        plt.plot(data_types, values, marker='o', label=http_version)\n",
    "    \n",
    "    for http_version, values in values_dict.items():\n",
    "        for i, value in enumerate(values):\n",
    "            plt.text(data_types[i], value, f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel(variable_name)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_performance(test_cases):\n",
    "    results = []\n",
    "    for case in test_cases:\n",
    "        data_type_name, http_version, parallel_count, num_repeats, network_latency = case\n",
    "        route = f\"data/performance/{data_type_name}_{http_version}_{parallel_count}_{num_repeats}_{network_latency}ms.sh\"\n",
    "\n",
    "        if not os.path.isfile(route):\n",
    "            print(f\"File {route} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(route)\n",
    "        start_time = df.loc[df.index[0], 'start_time']\n",
    "        end_time = df.loc[df.index[0], 'end_time']\n",
    "        total_average_latency = df.loc[df.index[0], 'total_average_latency']\n",
    "        total_average_throughput = df.loc[df.index[0], 'total_average_throughput']\n",
    "\n",
    "        results.append({\n",
    "            'data_type_name': data_type_name,\n",
    "            'http_version': http_version,\n",
    "            'parallel_count': parallel_count,\n",
    "            'num_repeats': num_repeats,\n",
    "            'network_latency': network_latency,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'total_average_latency': total_average_latency,\n",
    "            'total_average_throughput': total_average_throughput\n",
    "        })\n",
    "\n",
    "    time_intervals = [(result['start_time'], result['end_time']) for result in results]\n",
    "\n",
    "    return results, time_intervals\n",
    "\n",
    "def perform_comparison(test_cases, variable_name, second_variable_name, variable1_list, variable2_list):\n",
    "    results, time_intervals = compare_performance(test_cases)\n",
    "\n",
    "    cpu_data_groups = []\n",
    "    ram_data_groups = []\n",
    "    avg_latency = {http_version: [] for http_version in set(case[1] for case in test_cases)}\n",
    "    avg_throughput = {http_version: [] for http_version in set(case[1] for case in test_cases)}\n",
    "    avg_cpu_usage = {http_version: [] for http_version in set(case[1] for case in test_cases)}\n",
    "    avg_ram_usage = {http_version: [] for http_version in set(case[1] for case in test_cases)}\n",
    "    labels = []\n",
    "\n",
    "    for result in results:\n",
    "        data_type_name = result['data_type_name']\n",
    "        http_version = result['http_version']\n",
    "        start_time = result['start_time']\n",
    "        end_time = result['end_time']\n",
    "\n",
    "        label = f\"{data_type_name}_{http_version}\"\n",
    "        \n",
    "        if data_type_name not in labels:\n",
    "            labels.append(data_type_name)\n",
    "        \n",
    "        avg_latency[http_version].append(result['total_average_latency'])\n",
    "        avg_throughput[http_version].append(result['total_average_throughput'])\n",
    "\n",
    "        cpu_data = fetch_data(cpu_query, start_time, end_time)\n",
    "        cpu_timestamps, cpu_values = process_data(cpu_data)\n",
    "        cpu_normalized_timestamps, _ = normalize_timestamps(cpu_timestamps)\n",
    "        cpu_data_groups.append((cpu_normalized_timestamps, cpu_values, label))\n",
    "        avg_cpu_usage[http_version].append(sum(cpu_values) / len(cpu_values))\n",
    "\n",
    "        ram_data = fetch_data(ram_query, start_time, end_time)\n",
    "        ram_timestamps, ram_values = process_data(ram_data)\n",
    "        ram_normalized_timestamps, _ = normalize_timestamps(ram_timestamps)\n",
    "        ram_data_groups.append((ram_normalized_timestamps, ram_values, label))\n",
    "        avg_ram_usage[http_version].append(sum(ram_values) / len(ram_values))\n",
    "\n",
    "    file_suffix = f\"{variable1_list}_{variable2_list}_{test_cases[0][2]}_{test_cases[0][3]}_{test_cases[0][4]}\"\n",
    "\n",
    "    # Plot \n",
    "    cpu_output_file = f\"data/performance/cpu/{file_suffix}.png\"\n",
    "    plot_grouped_data(cpu_data_groups, 'CPU Usage (%)', 'CPU Usage Comparison', cpu_output_file)\n",
    "\n",
    "    ram_output_file = f\"data/performance/ram/{file_suffix}.png\"\n",
    "    plot_grouped_data(ram_data_groups, 'RAM Usage (%)', 'RAM Usage Comparison', ram_output_file)\n",
    "\n",
    "    avg_latency_output_file = f\"data/performance/latency/{file_suffix}.png\"\n",
    "    plot_avg_data(avg_latency, labels, 'Average Latency (s)', 'Average Latency Comparison', avg_latency_output_file, variable_name)\n",
    "\n",
    "    avg_throughput_output_file = f\"data/performance/throughput/{file_suffix}.png\"\n",
    "    plot_avg_data(avg_throughput, labels, 'Average Throughput', 'Average Throughput Comparison', avg_throughput_output_file, variable_name, is_throughput=True)\n",
    "\n",
    "    avg_cpu_usage_output_file = f\"data/performance/avg_cpu_usage/{file_suffix}.png\"\n",
    "    plot_avg_data(avg_cpu_usage, labels, 'Average CPU Usage (%)', 'Average CPU Usage Comparison', avg_cpu_usage_output_file, variable_name)\n",
    "\n",
    "    avg_ram_usage_output_file = f\"data/performance/avg_ram_usage/{file_suffix}.png\"\n",
    "    plot_avg_data(avg_ram_usage, labels, 'Average RAM Usage (%)', 'Average RAM Usage Comparison', avg_ram_usage_output_file, variable_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d9f67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_with_type_http():\n",
    "    # Constants\n",
    "    parallel_count = 5\n",
    "    num_repeats = 10\n",
    "    network_latency = 0  # in milliseconds\n",
    "\n",
    "    data_types = [\"text\", \"picture\", \"music\",  \"video\"]\n",
    "    http_versions = [\"http1\", \"http1_ssl\", \"http2\", \"http3\"]\n",
    "\n",
    "    # Create an array of data\n",
    "    test_cases = [(data_type, http_version, parallel_count, num_repeats, network_latency) for data_type in data_types for http_version in http_versions]\n",
    "\n",
    "    variable1_list = \"_\".join(data_types)\n",
    "    variable2_list = \"_\".join(http_versions)\n",
    "\n",
    "    perform_comparison(test_cases, 'data_type_name', 'http_version', variable1_list, variable2_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_with_type_http()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
